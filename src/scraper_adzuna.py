"""
Scraper pour r√©cup√©rer les offres d'emploi depuis l'API Adzuna
"""

import requests
import json
import time
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional


class AdzunaJobScraper:
    """
    Scraper pour r√©cup√©rer toutes les offres d'emploi depuis l'API Adzuna
    """
    
    def __init__(self, app_id: str, app_key: str, base_url: str = "http://api.adzuna.com/v1/api/jobs/fr/search"):
        self.app_id = app_id
        self.app_key = app_key
        self.base_url = base_url
        self.results_per_page = 50
        self.session = requests.Session()
        
        # D√©finir le r√©pertoire racine du projet (parent de src/)
        self.project_root = Path(__file__).parent.parent
        self.data_dir = self.project_root / "data"
        
        # Cr√©er le r√©pertoire data s'il n'existe pas
        self.data_dir.mkdir(exist_ok=True)
        
    def get_jobs_page(self, page: int, search_term: str = "data") -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re une page sp√©cifique d'offres d'emploi
        
        Args:
            page: Num√©ro de la page (commence √† 1)
            search_term: Terme de recherche
            
        Returns:
            R√©ponse JSON de l'API ou None en cas d'erreur
        """
        url = f"{self.base_url}/{page}"
        params = {
            'app_id': self.app_id,
            'app_key': self.app_key,
            'results_per_page': self.results_per_page,
            'what': search_term
        }
        
        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"Erreur lors de la requ√™te page {page}: {e}")
            return None
    
    def scrape_all_jobs(self, search_term: str = "data", max_pages: Optional[int] = None, delay: float = 1.0) -> List[Dict[str, Any]]:
        """
        R√©cup√®re toutes les offres d'emploi en parcourant toutes les pages
        
        Args:
            search_term: Terme de recherche
            max_pages: Nombre maximum de pages √† r√©cup√©rer (None = toutes)
            delay: D√©lai en secondes entre les requ√™tes
            
        Returns:
            Liste de toutes les offres d'emploi
        """
        all_jobs = []
        page = 1
        total_results = None
        
        print(f"D√©but du scraping pour le terme: '{search_term}'")
        
        while True:
            if max_pages and page > max_pages:
                print(f"Limite de pages atteinte: {max_pages}")
                break
                
            print(f"R√©cup√©ration de la page {page}...")
            
            response_data = self.get_jobs_page(page, search_term)
            
            if not response_data:
                print(f"Erreur lors de la r√©cup√©ration de la page {page}")
                break
            
            # R√©cup√©rer les informations sur le total la premi√®re fois
            if total_results is None:
                total_results = response_data.get('count', 0)
                total_pages = (total_results + self.results_per_page - 1) // self.results_per_page
                print(f"Total d'offres trouv√©es: {total_results}")
                print(f"Nombre total de pages: {total_pages}")
            
            # R√©cup√©rer les offres de cette page
            jobs = response_data.get('results', [])
            
            if not jobs:
                print(f"Aucune offre trouv√©e sur la page {page}. Fin du scraping.")
                break
            
            all_jobs.extend(jobs)
            print(f"Page {page}: {len(jobs)} offres r√©cup√©r√©es (Total: {len(all_jobs)})")
            
            # V√©rifier si c'est la derni√®re page
            if len(jobs) < self.results_per_page:
                print("Derni√®re page atteinte.")
                break
            
            page += 1
            
            # D√©lai entre les requ√™tes pour √©viter de surcharger l'API
            if delay > 0:
                time.sleep(delay)
        
        print(f"Scraping termin√©. Total d'offres r√©cup√©r√©es: {len(all_jobs)}")
        return all_jobs
    
    def save_to_json(self, jobs: List[Dict[str, Any]], filename: Optional[str] = None, search_term: str = "data") -> Path:
        """
        Sauvegarde les offres d'emploi dans un fichier JSON
        
        Args:
            jobs: Liste des offres d'emploi
            filename: Nom du fichier (optionnel, par d√©faut jobs_{search_term}.json)
            search_term: Terme de recherche utilis√©
            
        Returns:
            Chemin Path du fichier sauvegard√©
        """
        if filename is None:
            filename = f"jobs_{search_term}.json"
        
        # Utiliser le r√©pertoire data/ du projet
        filepath = self.data_dir / filename
        
        # Pr√©parer les donn√©es √† sauvegarder
        output_data = {
            "metadata": {
                "search_term": search_term,
                "total_jobs": len(jobs),
                "scraping_date": datetime.now().isoformat(),
                "api_source": "Adzuna"
            },
            "jobs": jobs
        }
        
        # Sauvegarder en JSON
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"Donn√©es sauvegard√©es dans: {filepath}")
        return filepath


def load_config(config_path: Optional[Path] = None) -> Optional[Dict]:
    """
    Charge la configuration depuis le fichier config.json
    
    Args:
        config_path: Chemin vers le fichier config.json (optionnel)
    
    Returns:
        dict: Configuration avec les cl√©s API ou None en cas d'erreur
    """
    if config_path is None:
        # Chercher config.json dans le dossier src/
        src_dir = Path(__file__).parent
        config_path = src_dir / "config.json"
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except FileNotFoundError:
        print(f"ERREUR: Fichier de configuration non trouv√©: {config_path}")
        print("Cr√©ez un fichier config.json bas√© sur config.example.adzuna.json")
        print(f"Le fichier doit √™tre plac√© dans le dossier src/: {config_path}")
        return None
    except json.JSONDecodeError as e:
        print(f"ERREUR: Le fichier config.json n'est pas un JSON valide: {e}")
        return None


def main():
    """
    Fonction principale pour ex√©cuter le scraping
    """
    # Charger la configuration
    config = load_config()
    if not config:
        return
    
    # R√©cup√©rer les cl√©s API
    adzuna_config = config.get('adzuna', {})
    APP_ID = adzuna_config.get('app_id')
    APP_KEY = adzuna_config.get('app_key')
    
    if not APP_ID or not APP_KEY:
        print("ERREUR: Cl√©s API manquantes dans le fichier config.json")
        print("V√©rifiez que app_id et app_key sont pr√©sents dans la section 'adzuna'")
        return
    
    
    # Param√®tres de recherche
    search_term = "data"  # Terme de recherche
    max_pages = 700  # None = toutes les pages, ou d√©finir un nombre pour limiter
    delay = 0.2  # D√©lai en secondes entre les requ√™tes
    
    # Cr√©er le scraper
    scraper = AdzunaJobScraper(APP_ID, APP_KEY)
    
    try:
        # R√©cup√©rer toutes les offres
        all_jobs = scraper.scrape_all_jobs(
            search_term=search_term,
            max_pages=max_pages,
            delay=delay
        )
        
        if all_jobs:
            # Sauvegarder les r√©sultats
            filepath = scraper.save_to_json(all_jobs, search_term=search_term)
            print(f"\n‚úÖ Scraping termin√© avec succ√®s!")
            print(f"üìä Nombre total d'offres: {len(all_jobs)}")
            print(f"üíæ Fichier sauvegard√©: {filepath}")
        else:
            print("Aucune offre r√©cup√©r√©e.")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Scraping interrompu par l'utilisateur.")
    except Exception as e:
        print(f"‚ùå Erreur inattendue: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

