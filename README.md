# ğŸ’¼ JobMarket - Analyse du MarchÃ© de l'Emploi DATA

> Projet de Data Engineering - Recensement et analyse des offres d'emploi dans le domaine de la DATA en France

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.10-red.svg)](https://airflow.apache.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![API](https://img.shields.io/badge/API-Adzuna-orange.svg)](https://developer.adzuna.com/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![Pandas](https://img.shields.io/badge/pandas-Data%20Analysis-green.svg)](https://pandas.pydata.org/)

---

## ğŸ“‹ Ã€ propos du projet

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'une **formation de Data Engineer** au sein de l'organisme Data Scientist. Il a pour objectif de :

- ğŸ” **Collecter** automatiquement les offres d'emploi liÃ©es aux mÃ©tiers de la DATA
- ğŸ“Š **Analyser** les tendances du marchÃ© de l'emploi (salaires, compÃ©tences, localisation)
- ğŸ“ˆ **Visualiser** les insights pour comprendre le secteur DATA en France
- ğŸ› ï¸ **Mettre en pratique** les compÃ©tences en data engineering (API, ETL, analyse)

### DonnÃ©es collectÃ©es

- **35 000+ offres d'emploi** rÃ©cupÃ©rÃ©es via l'API Adzuna
- Recherche sur le terme **"data"** (Data Engineer, Data Analyst, Data Scientist, etc.)
- DonnÃ©es enrichies : salaires, localisation GPS, type de contrat, descriptions

---

## ğŸš€ Technologies utilisÃ©es

### Backend & Collecte
- **Python 3.8+** - Langage principal
- **Requests** - Appels API HTTP
- **Adzuna API** - Source de donnÃ©es d'emploi

### Orchestration & ETL
- **Apache Airflow 2.10** - Orchestrateur de workflows
- **PostgreSQL 16** - Base de donnÃ©es relationnelle
- **Docker & Docker Compose** - Containerisation
- **psycopg2** - Connecteur PostgreSQL

### Analyse & Visualisation
- **Pandas** - Manipulation et analyse des donnÃ©es
- **NumPy** - Calculs numÃ©riques
- **Matplotlib** - Visualisations statiques
- **Seaborn** - Visualisations statistiques avancÃ©es
- **Jupyter Notebook** - Environnement d'analyse interactif
- **DBeaver** - Client SQL et visualisation

### Outils
- **Git** - Gestion de versions
- **JSON** - Format de stockage temporaire

---

## ğŸ“ Structure du projet

```
JobMarket/
â”‚
â”œâ”€â”€ README.md                       # Ce fichier
â”œâ”€â”€ ARCHITECTURE.md                 # Architecture du projet
â”œâ”€â”€ DECISIONS.md                    # Justifications des choix techniques
â”œâ”€â”€ .gitignore                      # Exclusions Git
â”œâ”€â”€ requirements.txt                # DÃ©pendances du projet
â”œâ”€â”€ docker-compose.yml             # Configuration Docker (Postgres + Airflow)
â”‚
â”œâ”€â”€ docs/                           # ğŸ“š Documentation dÃ©taillÃ©e
â”‚   â”œâ”€â”€ AIRFLOW_SETUP.md           # Guide Airflow
â”‚   â”œâ”€â”€ AIRFLOW_VARIABLES.md       # Config TEST/PROD
â”‚   â”œâ”€â”€ DATABASE_SETUP.md          # Guide PostgreSQL
â”‚   â””â”€â”€ DBEAVER_SETUP.md           # Guide DBeaver
â”‚
â”œâ”€â”€ dags/                           # ğŸ”„ DAGs Airflow
â”‚   â””â”€â”€ jobmarket_etl_pipeline.py  # Pipeline ETL principal
â”‚
â”œâ”€â”€ src/                            # ğŸŸ¢ Code source
â”‚   â”œâ”€â”€ __init__.py                # Package Python
â”‚   â”œâ”€â”€ config.json                # ClÃ©s API (non versionnÃ©)
â”‚   â”œâ”€â”€ config.example.adzuna.json # Template de configuration
â”‚   â”œâ”€â”€ scraper_adzuna.py          # Script de scraping Adzuna
â”‚   â”œâ”€â”€ db_config.py               # Configuration PostgreSQL centralisÃ©e
â”‚   â””â”€â”€ db_loader.py               # Chargeur de donnÃ©es dans PostgreSQL
â”‚
â”œâ”€â”€ sql/                            # ğŸ—„ï¸ Scripts SQL
â”‚   â”œâ”€â”€ init/                      # Scripts d'initialisation (auto-exec au 1er dÃ©marrage)
â”‚   â”‚   â”œâ”€â”€ 01_create_schemas.sql  # CrÃ©ation des schÃ©mas (raw, staging, analytics)
â”‚   â”‚   â”œâ”€â”€ 02_create_raw_tables.sql
â”‚   â”‚   â”œâ”€â”€ 03_create_staging_tables.sql
â”‚   â”‚   â”œâ”€â”€ 04_create_analytics_tables.sql
â”‚   â”‚   â””â”€â”€ 05_create_views.sql
â”‚   â””â”€â”€ transformations/           # Scripts de transformation
â”‚       â”œâ”€â”€ 01_load_staging.sql    # RAW â†’ STAGING
â”‚       â”œâ”€â”€ 02_load_analytics.sql  # STAGING â†’ ANALYTICS
â”‚       â””â”€â”€ 03_refresh_all.sql     # Refresh complet
â”‚
â”œâ”€â”€ data/                           # ğŸ“Š DonnÃ©es temporaires (ignorÃ© par Git)
â”‚   â”œâ”€â”€ .gitkeep                   # Garde le dossier dans Git
â”‚   â””â”€â”€ jobs_data.json             # JSON temporaire avant PostgreSQL
â”‚
â”œâ”€â”€ notebooks/                      # ğŸ““ Analyses Jupyter (legacy)
â”‚   â””â”€â”€ analysis.ipynb             # Notebook d'analyse initial
â”‚
â”œâ”€â”€ logs/                           # ğŸ“ Logs Airflow (ignorÃ© par Git)
â”‚
â”œâ”€â”€ tests/                          # ğŸ§ª Tests unitaires (Ã  venir)
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ archive/                        # ğŸ“¦ Anciennes implÃ©mentations
    â”œâ”€â”€ Adzuna API/                # Ancienne structure (obsolÃ¨te)
    â””â”€â”€ France Travail API/        # Ancienne API (obsolÃ¨te)
```

---

## ğŸ”§ Installation

### DÃ©marrage rapide

```bash
# 1. Cloner le projet
git clone https://github.com/votre-username/JobMarket.git
cd JobMarket

# 2. Configurer les clÃ©s API Adzuna
cp src/config.example.adzuna.json src/config.json
# Ã‰diter src/config.json avec vos clÃ©s (https://developer.adzuna.com/)

# 3. DÃ©marrer l'infrastructure Docker
docker-compose up -d

# 4. AccÃ©der Ã  Airflow
# http://localhost:8080 (admin/admin)
```

### ğŸ“– Guide d'installation complet

Pour une installation dÃ©taillÃ©e Ã©tape par Ã©tape avec toutes les explications, consultez :

ğŸ‘‰ **[ARCHITECTURE.md - Flux d'exÃ©cution](ARCHITECTURE.md#-flux-dexÃ©cution---chronologie)**

Ce guide couvre :
- âœ… Installation initiale complÃ¨te (venv, dÃ©pendances)
- âœ… Configuration dÃ©taillÃ©e de Docker
- âœ… Initialisation PostgreSQL et Airflow
- âœ… Configuration de la connexion Ã  la base de donnÃ©es
- âœ… Premier lancement du pipeline
- âœ… Passage en production
- âœ… Monitoring et maintenance

---

### Analyse des donnÃ©es

#### ğŸ”¹ Avec DBeaver (RecommandÃ©)

1. Connectez-vous Ã  PostgreSQL (voir [docs/DBEAVER_SETUP.md](docs/DBEAVER_SETUP.md))


#### ğŸ”¹ Avec Jupyter Notebook (Legacy)(Plus utilisÃ© depuis le passage Ã  SQL)

```bash
jupyter notebook notebooks/analysis.ipynb
```

---

## ğŸ“Š RÃ©sultats et Analyses

### Statistiques clÃ©s

- **35 000+ offres** collectÃ©es dans le domaine DATA
- Couverture nationale (toute la France)
- DonnÃ©es incluant :
  - ğŸ’° Fourchettes salariales (min/max)
  - ğŸ“ Localisation prÃ©cise (GPS + ville)
  - ğŸ“ Descriptions complÃ¨tes des postes
  - ğŸ¢ Informations entreprises
  - ğŸ“„ Types de contrat (CDI, CDD, freelance)
  - ğŸ·ï¸ CatÃ©gories d'emploi

### Insights disponibles

Le notebook d'analyse permet d'explorer :
- Distribution gÃ©ographique des offres DATA
- Analyse des salaires par type de poste
- CompÃ©tences les plus demandÃ©es
- Tendances par type de contrat
- Entreprises qui recrutent le plus

---

## ğŸ§  DÃ©cisions Techniques

### Pourquoi Adzuna plutÃ´t que France Travail ?

Le projet a initialement utilisÃ© l'API France Travail (ex-PÃ´le Emploi), mais a migrÃ© vers Adzuna pour :
- âœ… **Meilleure qualitÃ© des donnÃ©es** (descriptions plus riches)
- âœ… **Volume supÃ©rieur** (35k vs 7k offres)
- âœ… **Couverture Ã©tendue** (agrÃ©gateur multi-sources)
- âœ… **SimplicitÃ© d'utilisation** (pas d'OAuth2 complexe)
- âœ… **DonnÃ©es structurÃ©es** (salaires, GPS, mÃ©tadonnÃ©es)

ğŸ‘‰ **Voir le document [DECISIONS.md](DECISIONS.md)** pour le comparatif dÃ©taillÃ©.

---

## ğŸ—‚ï¸ Archives

L'ancienne implÃ©mentation utilisant France Travail API est archivÃ©e dans `archive/France Travail API/`.

**Raison de l'archivage** : QualitÃ© et volume des donnÃ©es insuffisants.

Voir `archive/France Travail API/README_ARCHIVE.md` pour plus de dÃ©tails.

---

## ğŸ“š Documentation

### ğŸ“‹ Documentation principale

- **[ARCHITECTURE.md](ARCHITECTURE.md)** - ğŸ—ï¸ Architecture complÃ¨te avec schÃ©mas visuels
- **[DECISIONS.md](DECISIONS.md)** - ğŸ§  Justifications des choix techniques

### ğŸ“– Guides dÃ©taillÃ©s

- **[docs/AIRFLOW_SETUP.md](docs/AIRFLOW_SETUP.md)** - ğŸš€ Guide complet Airflow (installation, DAG, troubleshooting)
- **[docs/AIRFLOW_VARIABLES.md](docs/AIRFLOW_VARIABLES.md)** - ğŸ›ï¸ Configuration mode TEST/PRODUCTION pour le scraping
- **[docs/DATABASE_SETUP.md](docs/DATABASE_SETUP.md)** - ğŸ—„ï¸ Guide PostgreSQL avec Docker
- **[docs/DBEAVER_SETUP.md](docs/DBEAVER_SETUP.md)** - ğŸ”§ Configuration DBeaver pour connexion DB

### ğŸ”— Ressources externes

- [src/config.example.adzuna.json](src/config.example.adzuna.json) - Template de configuration
- [Documentation API Adzuna](https://developer.adzuna.com/activedocs) - API officielle
- [Archive France Travail](archive/France%20Travail%20API/README_ARCHIVE.md) - Pourquoi archivÃ©

---

## ğŸ“ Contexte de formation

Ce projet fait partie d'une formation en **Data Engineering** et dÃ©montre les compÃ©tences suivantes :

- âœ… **Collecte de donnÃ©es** via API REST
- âœ… **Orchestration ETL** avec Apache Airflow
- âœ… **Base de donnÃ©es** PostgreSQL (schemas, tables, views)
- âœ… **Containerisation** avec Docker & Docker Compose
- âœ… **Transformations SQL** (Raw â†’ Staging â†’ Analytics)
- âœ… **Gestion des donnÃ©es** (JSON, pandas, SQL)
- âœ… **Analyse exploratoire** (EDA)
- âœ… **Visualisation de donnÃ©es**
- âœ… **Versioning et documentation** (Git, README)
- âœ… **Bonnes pratiques** (environnements virtuels, .gitignore, sÃ©curitÃ© des clÃ©s)

---

## ğŸ“ˆ AmÃ©liorations futures

- [x] ~~Automatiser la collecte quotidienne/hebdomadaire~~ âœ… (Airflow)
- [x] ~~Stocker les donnÃ©es dans une base PostgreSQL~~ âœ…
- [ ] CrÃ©er un moteur de recherche interactif (Streamlit)
- [ ] Ajouter des tests de qualitÃ© de donnÃ©es (Great Expectations)
- [ ] IntÃ©grer d'autres sources de donnÃ©es (technologies les plus recherchÃ©es : cloud, etl...) + extraire des descriptions les technos
- [ ] Ajouter un systÃ¨me d'alerting (emails Airflow) selon les prÃ©fÃ©rences d'un user
- [ ] CrÃ©er des vues pour Machine Learning (prÃ©diction de salaires)

---

## ğŸ‘¨â€ğŸ’» Auteur

DÃ©veloppÃ© dans le cadre d'une formation en Data Engineering.

---

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif.

---

## ğŸ™ Remerciements

- [Adzuna](https://www.adzuna.fr/) pour l'accÃ¨s Ã  leur API
- La communautÃ© Python pour les excellentes librairies d'analyse de donnÃ©es
